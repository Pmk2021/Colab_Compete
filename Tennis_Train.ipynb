{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import statistics\n",
    "import torch.distributions as tdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(x):\n",
    "    return torch.from_numpy(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy_Net, self).__init__()\n",
    "        self.l1 = nn.Linear(24,64)\n",
    "        self.l2 = nn.Linear(64,64)\n",
    "        self.l3 = nn.Linear(64,2)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = F.relu(self.l1(state))\n",
    "        state = F.relu(self.l2(state))\n",
    "        state = F.tanh(self.l3(state))\n",
    "        return state\n",
    "\n",
    "    \n",
    "policy=Policy_Net()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 0.9999)\n",
    "\n",
    "policy_1=policy\n",
    "optimizer_1 = optim.Adam(policy.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic_Net, self).__init__()\n",
    "        self.l1 = nn.Linear(48,128)\n",
    "        self.l2 = nn.Linear(128,128)\n",
    "        self.l3 = nn.Linear(128,2)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = F.relu(self.l1(state))\n",
    "        state = F.relu(self.l2(state))\n",
    "        state = F.tanh(self.l3(state))\n",
    "        return state\n",
    "    \n",
    "\n",
    "value_function=Critic_Net()\n",
    "optimizer_critic = optim.Adam(value_function.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advantage(rewards, critic, states, l = .96):\n",
    "  value_est = critic(states)\n",
    "  value_est_0 = value_est[:-1]\n",
    "  value_est_1 = value_est[1:]\n",
    "  rewards = torch.tensor(rewards)\n",
    "  advantage = rewards[:-1] + discount_rate * value_est_1 - value_est_0\n",
    "  advantage = torch.cat((advantage,(rewards[-1]).view(1,2)))\n",
    "  return advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_loss(rewards, critic, states):\n",
    "  value_est = critic(states)\n",
    "  rewards = torch.tensor(rewards)\n",
    "  return torch.mean((value_est-rewards)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                      discount, epsilon, var, actor):\n",
    "\n",
    "    rewards = rewards[:,actor].view(-1,1)\n",
    "    # convert states to policy (or probability)\n",
    "    new_total_probs = policy(states)\n",
    "    dist = tdist.multivariate_normal.MultivariateNormal(new_total_probs, torch.eye(2) * var)\n",
    "    new_probs = dist.log_prob(actions)\n",
    "\n",
    "    ratio = torch.exp(new_probs-old_probs)\n",
    "    \n",
    "    clipped_loss = torch.where(ratio > torch.tensor(1+epsilon), torch.tensor(1+epsilon), ratio)\n",
    "    clipped_loss = torch.where(clipped_loss < torch.tensor(1-epsilon),  torch.tensor(1-epsilon), clipped_loss)\n",
    "    clipped_loss = torch.min(ratio * rewards, clipped_loss * rewards)\n",
    "    #return torch.mean(torch.clamp(new_probs/old_probs * rewards, 1-epsilon * rewards, 1+epsilon * rewards))\n",
    "\n",
    "    \n",
    "    return torch.mean(clipped_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectories(env, policy, policy_1, Max_Time, var, training_mode = True):\n",
    "  env_info = env.reset(train_mode=training_mode)[brain_name]\n",
    "  s0 = prepro(env_info.vector_observations)\n",
    "  states = list()\n",
    "  actions = list()\n",
    "  rewards = list()\n",
    "  old_probs = list()\n",
    "\n",
    "  states_1 = list()\n",
    "  actions_1 = list()\n",
    "  rewards_1 = list()\n",
    "  old_probs_1 = list()\n",
    "    \n",
    "  \n",
    "  for step in range(Max_Time):\n",
    "    if 1 == 0:\n",
    "      action = 0\n",
    "    else:\n",
    "      #Gets Action\n",
    "      probs = policy((s0[0]-states_mean)/states_std)\n",
    "      probs = tdist.multivariate_normal.MultivariateNormal(probs, torch.eye(2) * var)\n",
    "    \n",
    "                                                           \n",
    "      probs_1 = policy_1((s0[1]-states_mean)/states_std)\n",
    "      probs_1 = tdist.multivariate_normal.MultivariateNormal(probs_1, torch.eye(2) * var)\n",
    "    \n",
    "      action = probs.sample()\n",
    "      action_1 = probs_1.sample()\n",
    "                                                           \n",
    "      probs = probs.log_prob(action)\n",
    "      probs_1 = probs_1.log_prob(action_1)\n",
    "                                                           \n",
    "      #Does Action\n",
    "    env_info = env.step((torch.stack((torch.clamp(action,-1,1),torch.clamp(action_1,-1,1)),0).detach().numpy()))[brain_name]           # send all actions to tne environment\n",
    "    state = env_info.vector_observations         # get next state (for each agent)\n",
    "    reward = env_info.rewards                         # get reward (for each agent)\n",
    "    done = env_info.local_done       \n",
    "    #Adds to experience\n",
    "    state = prepro(state)\n",
    "    if step > -1:\n",
    "      states.append(s0[0])\n",
    "      actions.append(action)\n",
    "      rewards.append(reward)\n",
    "      old_probs.append(probs)\n",
    "                                                           \n",
    "      states_1.append(s0[1])\n",
    "      actions_1.append(action_1)\n",
    "      rewards_1.append(reward)\n",
    "      old_probs_1.append(probs_1)   \n",
    "    s0 = state\n",
    "    if np.any(done):\n",
    "      break\n",
    "  scores = deepcopy(rewards)\n",
    "  discount_scores = torch.tensor(deepcopy(rewards))\n",
    "  #rewards = torch.tensor(rewards)\n",
    "  rewards = get_advantage(rewards, value_function,  torch.cat((torch.stack(states),torch.stack(states_1)),1))\n",
    "  for i in reversed(range(len(rewards)-1)):\n",
    "    rewards[i] += discount_rate *0.95* rewards[i + 1]\n",
    "    discount_scores[i] += discount_rate  * discount_scores[i+1]\n",
    "    #if len(advantage_rewards[-1][i:]) > horizon_len:\n",
    "    #  advantage_rewards[-1][i] += -1 *  advantage_rewards[-1][i + horizon_len - 1] * discount**horizon_len \n",
    "  #advantage_rewards[-1] = advantage_rewards[-1][:-horizon_len]   \n",
    "  rewards = deepcopy(discount_scores)\n",
    "  return old_probs, old_probs_1, states, states_1, actions, actions_1, rewards, scores, discount_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pmuralikrishnan\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 game average: 0.023800\n",
      "0.023800000362098218\n",
      "50 game average: 0.017000\n",
      "0.02040000032633543\n",
      "50 game average: 0.025000\n",
      "0.021933333687484263\n",
      "50 game average: 0.019800\n",
      "0.02140000034123659\n",
      "50 game average: 0.017400\n",
      "0.020600000329315662\n",
      "50 game average: 0.033400\n",
      "0.02273333369443814\n",
      "50 game average: 0.015000\n",
      "0.021628571775342737\n",
      "50 game average: 0.025000\n",
      "0.022050000354647638\n",
      "50 game average: 0.009600\n",
      "0.020666666999459266\n",
      "50 game average: 0.025400\n",
      "0.021140000339597464\n",
      "50 game average: 0.026800\n",
      "0.02165454580363902\n",
      "50 game average: 0.017600\n",
      "0.021316667009765904\n",
      "50 game average: 0.012000\n",
      "0.020600000330461905\n",
      "50 game average: 0.013600\n",
      "0.020100000322397265\n",
      "50 game average: 0.004000\n",
      "0.019026666971544426\n",
      "50 game average: 0.019400\n",
      "0.01905000030528754\n",
      "50 game average: 0.025400\n",
      "0.019423529722673052\n",
      "50 game average: 0.021600\n",
      "0.01954444475678934\n",
      "50 game average: 0.021200\n",
      "0.019631579261469214\n",
      "50 game average: 0.031200\n",
      "0.020210000324994325\n",
      "50 game average: 0.013600\n",
      "0.019895238415116357\n",
      "50 game average: 0.023400\n",
      "0.0200545457767492\n",
      "50 game average: 0.033400\n",
      "0.020634782939501432\n",
      "50 game average: 0.032800\n",
      "0.021141667009020846\n",
      "50 game average: 0.016000\n",
      "0.020936000338196755\n",
      "50 game average: 0.026000\n",
      "0.02113076957085958\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "episode = 10000\n",
    "discount_rate = .99\n",
    "epsilon = 1.0\n",
    "var = 1.0\n",
    "tmax = 1000\n",
    "SGD_epoch = 10\n",
    "SGD_epoch_2 = 30\n",
    "num_traj = 50\n",
    "batch_size = 32\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    train_var = var\n",
    "    old_probs, old_probs_1, states, states_1, actions, actions_1, rewards, scores, discount_scores = list(),list(),list(), list(), list(), list(), torch.tensor(list()) ,list(), torch.tensor(list())\n",
    "    for traj in range(num_traj):\n",
    "      old_probs_, old_probs_1_, states_, states_1_, actions_, actions_1_, rewards_, scores_, discount_scores_ = collect_trajectories(env, policy, policy_1, tmax, var)\n",
    "      \n",
    "      old_probs = old_probs + old_probs_\n",
    "      states = states + states_       \n",
    "      actions = actions + actions_\n",
    "        \n",
    "      old_probs_1 = old_probs_1 + old_probs_1_\n",
    "      states_1 = states_1 + states_1_\n",
    "      actions_1 = actions_1 + actions_1_\n",
    "\n",
    "      rewards = torch.cat((rewards,rewards_))\n",
    "      discount_scores = torch.cat((discount_scores,discount_scores_))\n",
    "      scores = scores + scores_\n",
    "      mean_rewards.append(np.max(sum(np.array(scores_))))\n",
    "    #old_probs, states, actions, rewards, scores = collect_trajectories(env, policy, tmax)\n",
    "        \n",
    "    #Normalize Rewards\n",
    "    \n",
    "\n",
    "    states_mean = (torch.mean(torch.stack(states),0) + 3 * states_mean)/4\n",
    "    states_std = (torch.std(torch.stack(states),0) + 3 * states_std)/4\n",
    "    #states = (torch.stack(states)-states_mean)/(states_std+0.0000001)\n",
    "    states = (torch.stack(states)-states_mean)/states_std\n",
    "    #states_1_mean = torch.mean(torch.stack(states_1),0)\n",
    "    #states_1_std = torch.std(torch.stack(states_1),0)\n",
    "    #states_1 = (torch.stack(states_1)-states_1_mean)/(states_1_std+0.0000001)\n",
    "    states_1 = (torch.stack(states_1)-states_mean)/states_std\n",
    "    rewards_mean = 0\n",
    "    rewards_std = 1\n",
    "    rewards_mean = torch.tensor([torch.mean(rewards[:,0]),torch.mean(rewards[:,1])])\n",
    "    rewards_std = torch.tensor([torch.std(rewards[:,0]),torch.std(rewards[:,1])])\n",
    "    rewards = [(i-rewards_mean)/(rewards_std+0.0001) for i in rewards]\n",
    "\n",
    "    total_rewards = np.sum(scores, axis=0)/num_traj\n",
    "    \n",
    "    actions = torch.stack(actions)\n",
    "    old_probs = torch.tensor(old_probs)\n",
    "    rewards = torch.stack(rewards)\n",
    "    actions_1 = torch.stack(actions_1)\n",
    "    old_probs_1 = torch.tensor(old_probs_1)\n",
    "\n",
    "    \n",
    "    # gradient ascent step\n",
    "    for _ in range(SGD_epoch):\n",
    "        \n",
    "        permutation = torch.randperm(len(states))\n",
    "\n",
    "        for i in range(0,len(states), batch_size):\n",
    "\n",
    "\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            old_probs_batch, states_batch,actions_batch,rewards_batch = old_probs[indices], states[indices],actions[indices],rewards[indices]\n",
    "\n",
    "            L = -clipped_surrogate(policy, old_probs_batch, states_batch, actions_batch, rewards_batch, discount_rate, epsilon, var, 0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            L.backward(retain_graph=True)\n",
    "            torch.nn.utils.clip_grad_norm_(policy.parameters(), 3.0)\n",
    "            optimizer.step()\n",
    "            del L\n",
    "        \n",
    "    for _ in range(SGD_epoch):\n",
    "\n",
    "        permutation = torch.randperm(len(states))\n",
    "\n",
    "        for i in range(0,len(states), batch_size):\n",
    "\n",
    "\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            old_probs_batch, states_batch,actions_batch,rewards_batch = old_probs_1[indices], states_1[indices],actions_1[indices],rewards[indices]\n",
    "\n",
    "            L_1 = -clipped_surrogate(policy_1, old_probs_batch, states_batch, actions_batch, rewards_batch, discount_rate, epsilon, var, 1)\n",
    "\n",
    "       \n",
    "\n",
    "            optimizer_1.zero_grad()\n",
    "            L_1.backward(retain_graph=True)\n",
    "            torch.nn.utils.clip_grad_norm_(policy_1.parameters(), 3.0)\n",
    "            optimizer_1.step()\n",
    "            del L_1\n",
    "    \n",
    "    for _ in range(SGD_epoch_2):\n",
    "        \n",
    "        permutation = torch.randperm(len(discount_scores))\n",
    "        \n",
    "        for i in range(0,len(states), batch_size):\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            states_1_batch, states_batch, scores_batch =  states_1[indices],states[indices],discount_scores[indices]\n",
    "\n",
    "            # uncomment to utilize your own clipped function!\n",
    "            L = critic_loss(scores_batch, value_function, torch.cat((states_batch,states_1_batch),1))\n",
    "\n",
    "            optimizer_critic.zero_grad()\n",
    "            L.backward()\n",
    "            optimizer_critic.step()\n",
    "            del L\n",
    "    \n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.9999\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    if var > 0.2:\n",
    "        var*=0.9995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if ((e+1)*num_traj)%50 ==0 :\n",
    "        print(\"50 game average: {1:f}\".format((e+1)*num_traj,np.mean(mean_rewards[-50:])))\n",
    "        print(np.mean(mean_rewards))\n",
    "        SGD_epoch_2 = 30\n",
    "        if len(mean_rewards) > 200 and np.mean(mean_rewards[-100:]) >= 0.5:\n",
    "            print('done')\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22905d7a898>]"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([np.mean(mean_rewards[i:i+100]) for i in range(len(mean_rewards[:-100:]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running trained Agent\n",
    "for i in range(5):\n",
    "    old_probs_, old_probs_1_, states_, states_1_, actions_, actions_1_, rewards_, scores_,a = collect_trajectories(env, policy, policy_1, tmax, 0.001, training_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2128, -1.2912,  0.4544, -0.5880,  1.2794,  1.3196,  0.4544, -0.5880,\n",
       "        -0.9202, -1.3651, -1.5929, -0.8868,  1.1796,  1.0772, -1.5929, -0.8868,\n",
       "        -1.5168, -1.5654, -0.1508, -0.3401,  1.1283,  0.9233, -0.1508, -0.3401])"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_1_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  6.2152, -30.0000,   5.9411,  -7.0216,   6.2152, -30.0000,  -0.9832,\n",
       "        -10.2356,   0.0000,  -0.0000,   6.0000,  -7.0216,   0.0000,  -0.0000,\n",
       "         -1.5000,  -7.2356,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000])"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "        -6.1311, -1.5000,  0.0000,  0.0000,  7.0216,  6.0000,  0.0000,  0.0000,\n",
       "        -6.0593, -0.9832,  0.7176,  6.2152,  7.0216,  5.9411,  0.7176,  6.2152])"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_1_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
